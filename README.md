# Human Activity Recognition using MediaPipe & LSTM

Human Activity Recognition (HAR) project that detects and classifies human actions such as **walking, running, jogging, boxing, hand waving, and clapping** in real time using a **webcam**, **MediaPipe Pose** for keypoint extraction, and an **LSTM** model for sequence classification.

> ğŸ“Œ This repository contains the full pipeline: data collection â†’ preprocessing â†’ model training â†’ real-time inference.

---

## âœ¨ Features

- Real-time webcam input for activity recognition  
- Pose estimation using **MediaPipe Pose** (33 body landmarks)  
- Sequence modeling with **LSTM** for temporal motion understanding  
- Supports multiple activities:
  - Walking  
  - Running  
  - Jogging  
  - Boxing  
  - Hand Waving  
  - Clapping  
- Modular code for:
  - Data collection & CSV generation  
  - Model training  
  - Inference & live demo  

---

## ğŸ§  Project Architecture

### 1. Data Collection

1. Capture frames from webcam  
2. Use **MediaPipe Pose** to detect skeleton  
3. Extract (x, y, visibility) for each of the 33 keypoints  
4. Save pose sequences to `.csv` along with the activity label  

### 2. Model Training

1. Load pose sequences from CSV  
2. Normalize / scale keypoints  
3. Create sliding windows of frames (e.g., 30â€“60 frames per sample)  
4. Train an **LSTM-based classifier** to predict activity from pose sequence  
5. Save trained model as `model.h5` or similar

### 3. Inference (Real-Time)

1. Read live frames from webcam  
2. Run MediaPipe Pose to get keypoints  
3. Build a sequence buffer of recent frames  
4. Pass sequence to LSTM model  
5. Display predicted activity label on the video stream

---

## ğŸ§© Tech Stack

- **Language:** Python  
- **Pose Estimation:** [MediaPipe Pose](https://developers.google.com/mediapipe/solutions/vision/pose)  
- **Deep Learning:** TensorFlow / Keras (LSTM) or PyTorch (if you prefer)  
- **Data Handling:** NumPy, Pandas  
- **Visualization:** OpenCV, Matplotlib  
- **Environment:** Jupyter Notebook / Python scripts

---

## ğŸ“ Repository Structure (suggested)

```bash
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw recorded CSVs
â”‚   â”œâ”€â”€ processed/           # Cleaned / merged datasets
â”œâ”€â”€ models/
â”‚   â””â”€â”€ lstm_har_model.h5    # Saved trained model
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb    # EDA / experiments
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ collect_data.py      # Webcam capture & CSV generation
â”‚   â”œâ”€â”€ train_model.py       # LSTM training script
â”‚   â”œâ”€â”€ inference.py         # Real-time inference
â”‚   â””â”€â”€ utils.py             # Helper functions
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ activities.png       # Activity collage image
â”‚   â”œâ”€â”€ mediapipe_pose.png   # Skeleton diagram
â”‚   â””â”€â”€ pipeline.png         # Flowchart of the pipeline
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
